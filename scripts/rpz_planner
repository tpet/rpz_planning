#!/usr/bin/env python
"""RPZ compliant planner."""
from __future__ import absolute_import, division, print_function
# from exploration.msg import Path
from geometry_msgs.msg import Pose, PoseStamped, Pose2D, Quaternion, Transform, TransformStamped, Twist
import math
from nav_msgs.msg import Path
import numpy as np
import rospy
from ros_numpy import msgify, numpify
from scipy.spatial import cKDTree
from sensor_msgs.msg import CameraInfo, PointCloud2
from tf.transformations import euler_from_quaternion, quaternion_from_euler
import tf2_ros
from threading import RLock
from timeit import default_timer as timer
import torch
import torch.nn.functional as fun
from visualization_msgs.msg import Marker, MarkerArray
# from yacs.config import CfgNode


# https://github.com/rbgirshick/yacs
# cfg = CfgNode()
# cfg.visibility_sphere_radius = 100.

np.set_printoptions(precision=2)


class DimOrder(object):
    YAW_X_Y = 'YawXY'
    X_Y_YAW = 'XYYaw'


def slots(msg):
    """Return message attributes (slots) as list."""
    return [getattr(msg, var) for var in msg.__slots__]


def array(msg):
    """Return message attributes (slots) as array."""
    return np.array(slots(msg))


def tf3to2(tf):
    """Convert Transform to Pose2D."""
    pose_2d = Pose2D()
    pose_2d.x = tf.translation.x
    pose_2d.y = tf.translation.y
    rpy = euler_from_quaternion(slots(tf.rotation))
    pose_2d.theta = rpy[2]
    return pose_2d


def pose_2d_from_3d(pose):
    """Convert Pose to Pose2D."""
    assert isinstance(pose, Pose)
    pose_2d = Pose2D()
    pose_2d.x = pose.position.x
    pose_2d.y = pose.position.y
    rpy = euler_from_quaternion(slots(pose.orientation))
    pose_2d.theta = rpy[2]
    return pose_2d


def pose_3d_from_2d(pose_2d):
    """Convert Pose2D to Pose."""
    assert isinstance(pose_2d, Pose2D)
    pose = Pose()
    pose.position.x = pose_2d.x
    pose.position.y = pose_2d.y
    rpy = 0.0, 0.0, pose_2d.theta
    q = quaternion_from_euler(*rpy)
    pose.orientation = Quaternion(*q)
    return pose


def transform(T, x):
    assert T.shape[0] == T.shape[1]
    assert T.shape[0] == x.shape[0] + 1
    if isinstance(T, np.ndarray):
        return np.matmul(T[:-1, :-1], x) + T[:-1, -1:]
    elif isinstance(T, torch.Tensor):
        return torch.matmul(T[:-1, :-1], x) + T[:-1, -1:]
    raise TypeError('Invalid argument type: %s', type(T))


def cloud_msg_to_rpz_tensor(msg, order=DimOrder.YAW_X_Y):
    """Convert cloud message to RPZ tensor of size (RPZ=3, YAW=8, H, W)."""
    assert isinstance(msg, PointCloud2)
    rospy.logdebug('Converting RPZ cloud in %s of size (%i, %i) with channels %s...'
                   % (msg.header.frame_id, msg.height, msg.width, ', '.join([f.name for f in msg.fields])))
    # TODO: Get yaw angles from channels?
    yaws = list(range(0, 360, 45))
    sz = (250, 248)
    assert (msg.height * msg.width == sz[0] * sz[1])

    cloud = numpify(msg).reshape(sz)
    print(cloud.dtype.names)

    # assert 'x' in cloud.dtype.names
    # assert 'roll_0' in cloud.dtype.names
    # assert 'pitch_0' in cloud.dtype.names
    # assert 'z_0' in cloud.dtype.names

    # Convert cloud to RPZ tensor of size (1, 3, 8, 250, 248)
    if order == DimOrder.YAW_X_Y:
        rpz = torch.full((3, 8) + sz, np.nan, dtype=torch.float32)
        for i, yaw in enumerate(yaws):
            rpz[0, 0, i, ...] = torch.tensor(cloud['roll_%i' % yaw], dtype=torch.float32)
            rpz[0, 1, i, ...] = torch.tensor(cloud['pitch_%i' % yaw], dtype=torch.float32)
            rpz[0, 2, i, ...] = torch.tensor(cloud['z_%i' % yaw], dtype=torch.float32)
    elif order == DimOrder.X_Y_YAW:
        rpz = torch.full((3,) + sz + (8,), np.nan, dtype=torch.float32)
        for i, yaw in enumerate(yaws):
            rpz[0, 0, ..., i] = torch.tensor(cloud['roll_%i' % yaw], dtype=torch.float32)
            rpz[0, 1, ..., i] = torch.tensor(cloud['pitch_%i' % yaw], dtype=torch.float32)
            rpz[0, 2, ..., i] = torch.tensor(cloud['z_%i' % yaw], dtype=torch.float32)
    else:
        raise ValueError('Invalid dimension order: %s' % order)

    return cloud, rpz


def cloud_to_grid_transform(cloud):
    t = timer()
    sz = cloud.shape
    x_cloud = []
    u_grid = []
    for i, j in ((0, 0), (0, 1), (1, 0)):
        # x = torch.tensor([cloud['x'][i, j],
        #                   cloud['y'][i, j]])d
        # u = torch.tensor([-1.0 + (i + 0.5) * 2 / sz[0],
        #                   -1.0 + (j + 0.5) * 2 / sz[1]])
        x = [cloud['x'][i, j], cloud['y'][i, j]]
        u = [-1.0 + (i + 0.5) * 2 / sz[0], -1.0 + (j + 0.5) * 2 / sz[1]]
        # Transpose
        # u = [-1.0 + (j + 0.5) * 2 / sz[1], -1.0 + (i + 0.5) * 2 / sz[0]]
        print('(%i, %i): x = (%.3f, %.3f), u = (%.3f, %.3f)' % (i, j, x[0], x[1], u[0], u[1]))
        x_cloud.append(x)
        u_grid.append(u)

    A = []
    b = []
    for x, u in zip(x_cloud, u_grid):
        A.append([x[0], x[1], 1.,   0.,   0., 0.])
        A.append([  0.,   0., 0., x[0], x[1], 1.])
        b.append([u[0]])
        b.append([u[1]])
    A = torch.tensor(A)
    b = torch.tensor(b)
    print('A\n%s' % A)
    print('b\n%s' % b)
    sol, _ = torch.solve(b, A)
    print('sol\n%s' % sol)

    cloud_to_grid = torch.eye(3)
    cloud_to_grid[:2, :] = sol.reshape((2, 3))

    print(u_grid)
    # x_in_grid = p2e(torch.matmul(cloud_to_grid, e2p(torch.transpose(torch.tensor(x_cloud), 1, 0))))
    x_in_grid = transform(cloud_to_grid, torch.tensor(x_cloud).transpose(1, 0))
    print(x_in_grid)

    rospy.logdebug('Cloud to grid transform computed (%.3f s).', timer() - t)
    return cloud_to_grid


def path_msg_to_xyyaw_tensor(msg, order=DimOrder.YAW_X_Y):
    """Convert path message to x, y, yaw tensor of size (N, XYY=3)."""
    assert isinstance(msg, Path)
    xyy = []
    for pose in msg.poses:
        pose_2d = pose_2d_from_3d(pose.pose)
        assert isinstance(pose_2d, Pose2D)
        if order == DimOrder.X_Y_YAW:
            xyy.append([pose_2d.x, pose_2d.y, pose_2d.theta])
        elif order == DimOrder.YAW_X_Y:
            xyy.append([pose_2d.theta, pose_2d.x, pose_2d.y])
        else:
            raise ValueError('Invalid dimension order: %s' % order)
    xyy = torch.tensor(xyy)
    return xyy


def rotation_angle_2d_from_matrix(mat):
    assert isinstance(mat, torch.Tensor)
    # Map-to-grid transform includes scale.
    if isinstance(mat, np.ndarray):
        angle = np.arctan2(mat[1, 0], mat[0, 0])
    elif isinstance(mat, torch.Tensor):
        angle = torch.atan2(mat[1, 0], mat[0, 0])
    else:
        angle = math.atan2(mat[1][0], mat[0][0])
    return angle


def xyyaw_to_grid(xyyaw, map_to_grid, order=DimOrder.YAW_X_Y):
    """Convert x, y, yaw to grid coordinates."""
    assert False, "Fix"
    yaw_0 = rotation_angle_2d_from_matrix(map_to_grid)
    rospy.logdebug('Grid yaw: %.3f', yaw_0.item())
    if order == DimOrder.YAW_X_Y:
        xy = torch.tensor([[x, y] for yaw, x, y in xyyaw]).transpose(1, 0)
    elif order == DimOrder.X_Y_YAW:
        xy = torch.tensor([[x, y] for x, y, yaw in xyyaw]).transpose(1, 0)
    else:
        raise ValueError('Invalid dimension order: %s' % order)
    # print(xy)
    rospy.logdebug('X, y in map: %s', xy)
    xy_grid = transform(map_to_grid, xy)
    # print(xy_grid)
    rospy.logdebug('X, y in grid: %s', xy)
    # TODO: Yaw offset direction?
    yaw_grid = [yaw - yaw_0 for _, _, yaw in xyyaw]
    xyyaw_grid = [[xy_grid[0, i].item(), xy_grid[1, i].item(), yaw_grid[i].item()] for i in range(len(yaw_grid))]
    rospy.loginfo('X, y, yaw in grid: %s', xyyaw_grid)
    return xyyaw_grid


def xyyaw_tensor_to_grid(xyyaw, map_to_grid, order=DimOrder.YAW_X_Y):
    """Convert x, y, yaw tensor of () to grid coordinates."""
    yaw_0 = rotation_angle_2d_from_matrix(map_to_grid)
    rospy.logdebug('Grid yaw: %.3f', yaw_0.item())
    if order == DimOrder.X_Y_YAW:
        # xy = xyyaw torch.tensor([[x, y] for x, y, yaw in xyyaw]).transpose(1, 0)
        xy = xyyaw[:, :2]
    elif order == DimOrder.YAW_X_Y:
        xy = xyyaw[:, 1:]
    else:
        raise ValueError('Invalid dimension order: %s' % order)
    rospy.logdebug('X, y in map: %s', xy)

    xy_grid = transform(map_to_grid, xy.transpose(1, 0))
    rospy.logdebug('X, y in grid: %s', xy_grid)

    # TODO: Yaw offset direction?
    yaw_grid = [yaw - yaw_0 for _, _, yaw in xyyaw]
    xyyaw_grid = [[xy_grid[0, i].item(), xy_grid[1, i].item(), yaw_grid[i].item()] for i in range(len(yaw_grid))]
    rospy.loginfo('X, y, yaw in grid: %s', xyyaw_grid)
    return xyyaw_grid


def smooth_rpz(rpz, sigma):
    # TODO: torch.nn.Conv3d
    # padding_mode='circular' for yaw
    # padding_mode='zeros' for xy
    # Use circular as the values near xy edges are often garbage anyway.
    # Pad xy edges with zeros if needed.
    pass


def interpolate_rpz(rpz, xyy):
    # TODO: Interpolate roll, pitch, z for given x, y, yaw.
    # TODO: https://pytorch.org/docs/master/nn.functional.html#grid-sample
    # input (N, C, D, H, W)
    # grid (N, D, H, W, 3)
    # mode = 'bilinear' | 'nearest' | 'bicubic'
    # padding_mode = 'zeros' | 'border' | 'reflection'
    # Circular padding mode not supported.
    # TODO: Create YawD + 2 to wrap yaw for interpolation.

    # Only bilinear in 5-D
    # mode = 'bilinear'
    torch.nn.functional.grid_sample(rpz, xyy)
    pass


def point_visibility(pts, origin):
    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html
    if isinstance(pts, np.ndarray):
        r = (pts - origin) ** 2
    if isinstance(pts, torch.Tensor):
        pass


def point_fov_mask(pts, cam):
    pass


def point_reward(pts, cam):
    pass


def tf_to_pose(tf):
    # tf = Transform()
    pose = Pose()
    pose.position.x = tf.translation.x
    pose.position.y = tf.translation.y
    pose.position.z = tf.translation.z
    pose.orientation = tf.rotation
    return pose


def tf_to_pose_stamped(tf):
    tf = TransformStamped()
    pose = PoseStamped()
    pose.header = tf.header
    pose.pose = tf_to_pose(tf.transform)
    return pose


def p2e(xh):
    x = xh[:-1, :]
    return x


def e2p(x):
    if isinstance(x, np.ndarray):
        xh = np.concatenate((x, np.ones((1, x.shape[1]))))
    if isinstance(x, torch.Tensor):
        xh = torch.cat((x, torch.ones((1, x.shape[1]))))
    return xh


class RPZPlanner(object):

    def __init__(self):
        self.map_frame = rospy.get_param('~map_frame', 'map')
        self.robot_frame = rospy.get_param('~robot_frame', 'base_footprint')
        self.max_age = rospy.get_param('~max_age', 1.0)

        # Keep only points inside a box for clearance check.
        # keep_cloud_box = rospy.get_param('~keep_cloud_box', [[-4.0, 4.0],
        #                                                      [-4.0, 4.0],
        #                                                      [-4.0, 4.0]])
        # self.keep_cloud_box = np.array(keep_cloud_box)
        # clearance_box = rospy.get_param('~clearance_box', [[-0.6, 0.6],
        #                                                    [-0.5, 0.5],
        #                                                    [ 0.0, 0.8]])
        # self.clearance_box = np.array(clearance_box)
        # self.show_clearance = rospy.get_param('~show_clearance_pos', [-10, 10])
        # self.min_points_obstacle = rospy.get_param('~min_points_obstacle', 1)

        self.num_cameras = rospy.get_param('~num_cameras', 1)
        device = rospy.get_param('~device', 'cuda:0' if torch.cuda.is_available() else 'cpu')
        self.device = torch.device(device)

        # Latest RPZ manifold
        # TODO: frame vs map
        self.rpz_lock = RLock()
        self.rpz_msg = None
        # self.roll = None
        # self.pitch = None
        # self.z = None
        self.rpz_cloud = None
        self.rpz = None
        self.map_to_grid = None
        self.grid_to_map = None

        # Latest point cloud map to cover
        self.map_lock = RLock()
        self.map_msg = None
        self.map = None  # n-by-3 cloud position array
        # self.map_x_index = None  # Index of above

        self.tf = tf2_ros.Buffer()
        self.tf_sub = tf2_ros.TransformListener(self.tf)

        self.path_pub = rospy.Publisher('optimized_path', Path, queue_size=2)
        # self.clearance_pub = rospy.Publisher('clearance', MarkerArray, queue_size=2)

        # Allow multiple cameras.
        self.cam_info_lock = RLock()
        self.cam_infos = [None] * self.num_cameras
        self.cam_info_subs = [rospy.Subscriber('camera_info_%i' % i, CameraInfo,
                                               lambda msg, i=i: self.cam_info_received(msg, i), queue_size=2)
                              for i in range(self.num_cameras)]

        self.rpz_sub = rospy.Subscriber('rpz', PointCloud2, self.rpz_received, queue_size=2)
        self.map_sub = rospy.Subscriber('map', PointCloud2, self.map_received, queue_size=2)
        self.path_sub = rospy.Subscriber('path', Path, self.path_received, queue_size=2)

    def lookup_transform(self, target_frame, source_frame, time,
                         no_wait_frame=None, timeout=0.0):

        timeout = rospy.Duration.from_sec(timeout)
        if no_wait_frame is None or no_wait_frame == target_frame:
            tf_s2t = self.tf.lookup_transform(target_frame, source_frame, time, timeout=timeout)
            return tf_s2t

        # Try to get exact transform from no-wait frame to target if available.
        # If not, use most recent transform.
        dont_wait = rospy.Duration.from_sec(0.0)
        try:
            tf_n2t = self.tf.lookup_transform(target_frame, self.odom_frame, time, timeout=dont_wait)
        except tf2_ros.TransformException as ex:
            tf_n2t = self.tf.lookup_transform(target_frame, self.odom_frame, rospy.Time(0))

        # Get the exact transform from source to no-wait frame.
        tf_s2n = self.tf.lookup_transform(self.odom_frame, source_frame, time, timeout=timeout)

        tf_s2t = TransformStamped()
        tf_s2t.header.frame_id = target_frame
        tf_s2t.header.stamp = time
        tf_s2t.child_frame_id = source_frame
        tf_s2t.transform = msgify(Transform,
                                  np.matmul(numpify(tf_n2t.transform),
                                            numpify(tf_s2n.transform)))
        return tf_s2t

    def get_robot_pose(self, target_frame):
        tf = self.lookup_transform(target_frame, self.robot_frame, rospy.Time.now(),
                                   timeout=0.5, no_wait_frame=self.odom_frame)
        pose = tf_to_pose(tf.transform)
        return pose

    def cam_info_received(self, msg, i):
        """Store camera calibration for i-th camera."""
        assert isinstance(msg, CameraInfo)
        assert isinstance(i, int)
        with self.cam_info_lock:
            if self.cam_infos[i] is None:
                rospy.loginfo('Got calibration for camera %i (%s).', i, msg.header.frame_id)
            self.cam_infos[i] = msg

    def rpz_received(self, msg):
        """Process and store RPZ manifold for use in planning."""
        t = timer()
        # assert isinstance(msg, PointCloud2)
        #
        # rospy.loginfo('RPZ: %s (%i, %i)' % (msg.header.frame_id, msg.height, msg.width))
        # sz = (8, 250, 248)
        # assert(msg.height * msg.width == sz[1] * sz[2])
        # cloud = numpify(msg)
        # roll = torch.full(sz, np.nan, dtype=torch.float32)
        # pitch = torch.full(sz, np.nan, dtype=torch.float32)
        # z = torch.full(sz, np.nan, dtype=torch.float32)
        # for i, yaw in enumerate(range(0, 360, 45)):
        #     roll[i, ...] = torch.tensor(cloud['roll_%i' % yaw], dtype=torch.float32).reshape(sz[1:])
        #     pitch[i, ...] = torch.tensor(cloud['pitch_%i' % yaw], dtype=torch.float32).reshape(sz[1:])
        #     z[i, ...] = torch.tensor(cloud['z_%i' % yaw], dtype=torch.float32).reshape(sz[1:])
        # rospy.loginfo(roll.shape)
        # with self.rpz_lock:
        #     self.rpz_msg = msg
        #     self.roll = roll
        #     self.pitch = pitch
        #     self.z = z

        # roll, pitch, z = msg_to_rpz_tensor(msg)
        cloud, rpz = cloud_msg_to_rpz_tensor(msg)
        cloud_to_grid = cloud_to_grid_transform(cloud)
        grid_to_cloud = torch.inverse(cloud_to_grid)
        with self.rpz_lock:
            self.rpz_msg = msg
            # self.roll = roll
            # self.pitch = pitch
            # self.z = z
            self.rpz_cloud = cloud
            # Yaw offset
            # p0 = np.array([self.rpz_cloud['x'][0, 0], self.rpz_cloud['y'][0, 0]])
            # p1 = np.array([self.rpz_cloud['x'][0, 1], self.rpz_cloud['y'][0, 1]])
            # p0 = torch.tensor([self.rpz_cloud['x'][0, 0], self.rpz_cloud['y'][0, 0]])
            # p1 = torch.tensor([self.rpz_cloud['x'][0, 1], self.rpz_cloud['y'][0, 1]])
            # x = (p1 - p0).norm()
            # yaw_offset = torch.atan2(self.rpz_cloud['y'][0, 1] - self.rpz_cloud['y'][0, 0],
            #                          self.rpz_cloud['x'][0, 1] - self.rpz_cloud['x'][0, 0])
            self.rpz = rpz
            self.map_to_grid = cloud_to_grid
            self.grid_to_map = grid_to_cloud

        rospy.loginfo('RPZ processed and stored (%.3f s).', (timer() - t))

    def map_received(self, msg):
        """Process and store map for use in planning."""
        assert isinstance(msg, PointCloud2)
        with self.map_lock:
            self.map_msg = msg

    def path_received(self, msg):
        assert isinstance(msg, Path)
        # http://docs.ros.org/en/melodic/api/nav_msgs/html/msg/Path.html

        with self.rpz_lock:
            if self.rpz_msg is None:
                rospy.logwarn('Skipping path. RPZ cloud not yet received.')
            assert isinstance(self.rpz_msg, PointCloud2)
            assert self.rpz_msg.header.frame_id == msg.header.frame_id
            rpz = self.rpz
            map_to_grid = self.map_to_grid

        with self.map_lock:
            if self.map_msg is None:
                rospy.logwarn('Skipping path. Map cloud not yet received.')
            assert isinstance(self.map_msg, PointCloud2)
            assert self.map_msg.header.frame_id == msg.header.frame_id

        if not msg.header.frame_id:
            rospy.logwarn_once('Map frame %s will be used instead of empty path frame.',
                               self.map_frame)
            msg.header.frame_id = self.map_frame
        # elif not self.map_frame:
        #     self.map_frame = msg.header.frame_id
        elif self.map_frame and msg.header.frame_id != self.map_frame:
            rospy.logwarn_once('Map frame %s will be used instead of path frame %s.',
                               self.map_frame, msg.header.frame_id)

        # Discard old messages.
        age = (rospy.Time.now() - msg.header.stamp).to_sec()
        if age > self.max_age:
            rospy.logwarn('Discarding path %.1f s > %.1f s old.', age, self.max_age)
            return

        # TODO: Convert path to x, y, yaw sequence.
        xyyaw = path_msg_to_xyyaw(msg)
        xyyaw_grid = xyyaw_to_grid(xyyaw, map_to_grid)

        xyyaw = path_msg_to_xyyaw_tensor(msg)

        # TODO: Optimize path.
        #   TODO: Interpolate RPZ for given x, y, yaw.


        #   TODO: Construct cameras.
        #   TODO: Compute visibility and reward.

        # TODO: Publish optimized path.
        self.path_pub.publish(msg)


if __name__ == '__main__':
    rospy.init_node('rpz_planner', log_level=rospy.DEBUG)
    node = RPZPlanner()
    rospy.spin()
